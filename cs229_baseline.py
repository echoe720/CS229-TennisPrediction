# -*- coding: utf-8 -*-
"""cs229_baseline.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1HRX8L_FBYSTUWgi3YVw7x2ITgD1LhBYQ
"""

import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from sklearn.metrics import accuracy_score
from sklearn.metrics import brier_score_loss
from sklearn.metrics import f1_score
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score

# Commented out IPython magic to ensure Python compatibility.
#this mounts your Google Drive to the Colab VM.
from google.colab import drive
drive.mount('/content/drive', force_remount=True)

# enter the foldername in the Shared Google Drive
FOLDERNAME = 'Shared drives/CS 229 Project'
assert FOLDERNAME is not None, "[!] Enter the foldername."

# now that we've mounted your Drive, this ensures that
# the Python interpreter of the Colab VM can load
# python files from within it.
import sys
sys.path.append('/content/drive/{}'.format(FOLDERNAME))

# %cd /content/drive/$FOLDERNAME/

# load data into vars
train_data = pd.read_csv('./train_points_data_original.csv')
val_data = pd.read_csv('./test_points_data_original.csv')
x_train = train_data.iloc[:, 1:82].to_numpy()
y_train = train_data.iloc[:, 82].to_numpy()

# print(y_train[2])

print('x_train.shape: ', x_train.shape)
print('y_train.shape: ', y_train.shape)

x_val = val_data.iloc[:, 1:82].to_numpy()
y_val = val_data.iloc[:, 82].to_numpy()


print('x_val.shape: ', x_val.shape)
print('y_val.shape: ', y_val.shape)



def sigmoid(x):
  return 1./(1 + np.exp(-x))

def parse_features(x):
  set_diffs = x[:,2] - x[:,3]
  game_diffs = x[:,4] - x[:, 5]
  return set_diffs, game_diffs

def parse_points(x):
  total = np.sum(x[:,-5:], axis=1)
  print(x[:,-5:].shape)
  return 2 * total - 5

def get_probs(sets, games):
  sets = sets + 2 * sigmoid(games) - 1
  return sigmoid(sets)

sigmoid(1.7)

sigmoid(-.7)

sets, games = parse_features(x_val)
y_pred = get_probs(sets, games)

np.mean(y_pred)

total = 0
# for i in range(len(y_pred)):
#   if y_pred[i] == 0.5:

#     y_pred[i] = sigmoid(games[i])
for i in range(len(y_pred)):
  if y_pred[i] == 0.5:
    total += 1
    noise = (np.random.rand() - 0.5) / 10000.
    y_pred[i] += noise
print(total)

y_out = y_pred >= 0.5

np.mean(y_out)

accuracy_score(y_val, y_out)

brier_score_loss(y_val, y_pred)

f1_score(y_val, y_out)

print(precision_score(y_val, y_out))
print(recall_score(y_val, y_out))

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.calibration import calibration_curve, CalibrationDisplay

#clf = LogisticRegression(random_state=0)
#clf.fit(x_train, y_train)
#y_prob = clf.predict_proba(x_val)[:, 2]
#clf.score(x_val, y_val)

prob_true, prob_pred = calibration_curve(y_val, y_pred, n_bins=10)
disp = CalibrationDisplay(prob_true, prob_pred, y_pred)
disp.plot()

from sklearn.utils.validation import column_or_1d
def calibration_error(y_true, y_prob, n_bins=10):
  y_true = column_or_1d(y_true)
  y_prob = column_or_1d(y_prob)

  bins = np.linspace(0.0, 1.0, n_bins + 1)
  binids = np.searchsorted(bins[1:-1], y_prob)

  bin_sums = np.bincount(binids, weights=y_prob, minlength=len(bins))
  bin_true = np.bincount(binids, weights=y_true, minlength=len(bins))
  bin_total = np.bincount(binids, minlength=len(bins))

  nonzero = bin_total != 0

  ece = np.sum(np.abs(prob_true - prob_pred) * (bin_total[nonzero] / len(y_val)))
  return ece

calibration_error(y_val, y_pred)

