# -*- coding: utf-8 -*-
"""cs229_lstm.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1jYO7zLFks-uBviZG42x1_jJs1L_bijGr
"""

import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.layers import Embedding
from tensorflow.keras.layers import LSTM
from tensorflow.keras.layers import Dropout
from tensorflow.keras.layers import SimpleRNN
from tensorflow.keras.layers import GRU
from sklearn.metrics import accuracy_score
from sklearn.metrics import brier_score_loss
from sklearn.metrics import f1_score, precision_score, recall_score
import matplotlib.pyplot as plt

# Commented out IPython magic to ensure Python compatibility.
#this mounts your Google Drive to the Colab VM.
from google.colab import drive
drive.mount('/content/drive', force_remount=True)

# enter the foldername in the Shared Google Drive
FOLDERNAME = 'Shared drives/CS 229 Project'
assert FOLDERNAME is not None, "[!] Enter the foldername."

# now that we've mounted your Drive, this ensures that
# the Python interpreter of the Colab VM can load
# python files from within it.
import sys
sys.path.append('/content/drive/{}'.format(FOLDERNAME))

# %cd /content/drive/$FOLDERNAME/

# load data into vars
train_data = pd.read_csv('./lstm_train.csv')
val_data = pd.read_csv('./lstm_test.csv')
x_train = train_data.iloc[:, 1:551].to_numpy().astype(np.float32)
y_train = train_data.iloc[:, 551].to_numpy().astype(np.float32)

# print(y_train[2])


print('x_train.shape: ', x_train.shape)
print('y_train.shape: ', y_train.shape)

x_val = val_data.iloc[:, 1:551].to_numpy().astype(np.float32)
y_val = val_data.iloc[:, 551].to_numpy().astype(np.float32)

x_train = np.expand_dims(x_train, 1)
x_val = np.expand_dims(x_val, 1)

print('x_val.shape: ', x_val.shape)
print('y_val.shape: ', y_val.shape)

n_classes = 1
n_features = x_train.shape[1]

model = Sequential()

model.add(LSTM(units=100, input_shape=(1, 550)))
model.add(Dense(1, activation='sigmoid'))
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
model.summary()
history = model.fit(x_train, y_train, epochs=15, validation_data=(x_val, y_val))

plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

y_pred = model.predict(x_val)
y_out = y_pred >= 0.5

y_val = y_val.astype(int)
np.min(y_val)
for i in range(y_val.shape[0]):
  if y_val[i] != 1 and y_val[i] != 0:
    print(y_val[i], i)
    y_val[i] = 0

accuracy_score(y_val, y_out)

brier_score_loss(y_val, y_out)

print(f1_score(y_val, y_out))
print(precision_score(y_val, y_out))
recall_score(y_val, y_out)

y_val = y_val.astype(int)
np.min(y_val)
for i in range(y_val.shape[0]):
  if y_val[i] != 1 and y_val[i] != 0:
    print(y_val[i], i)
#y_val[605] = 0

for i in range(y_train.shape[0]):
  if y_train[i] != 1 and y_train[i] != 0:
    print(y_train[i], i)

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.calibration import calibration_curve, CalibrationDisplay

prob_true, prob_pred = calibration_curve(y_val, y_pred, n_bins=10, strategy='quantile')
disp = CalibrationDisplay(prob_true, prob_pred, y_pred)
disp.plot(name="Calibration Curve for LSTM on Test Set")

from sklearn.utils.validation import column_or_1d
def calibration_error(y_true, y_prob, n_bins=10):
  y_true = column_or_1d(y_true)
  y_prob = column_or_1d(y_prob)

  bins = np.linspace(0.0, 1.0, n_bins + 1)
  binids = np.searchsorted(bins[1:-1], y_prob)

  bin_sums = np.bincount(binids, weights=y_prob, minlength=len(bins))
  bin_true = np.bincount(binids, weights=y_true, minlength=len(bins))
  bin_total = np.bincount(binids, minlength=len(bins))

  nonzero = bin_total != 0

  ece = np.sum(np.abs(prob_true - prob_pred) * (bin_total[nonzero] / len(y_val)))
  return ece

calibration_error(y_val, y_pred)

game_data = pd.read_csv('./nadal_zverev.csv')
x_game = game_data.iloc[:, 1:551].to_numpy().astype(np.float32)
y_game = game_data.iloc[:, 551].to_numpy().astype(np.float32)

x_game = np.expand_dims(x_game, 1)

nadal_pred = model.predict(x_game)
zverev_pred = 1 - nadal_pred

num_points = nadal_pred.shape[0]
plt.plot(np.arange(num_points), nadal_pred, c='red', label='Nadal')
plt.plot(np.arange(num_points), zverev_pred, c='black', label='Zverev')
plt.xlabel('Number of Points') 
plt.ylabel('Probability of Winning') 
plt.title('Predictions Across Nadal-Zverev 2018')
plt.legend(['Nadal', 'Zverev'])
plt.axvline(x=40,color='red', linestyle='dotted', linewidth=3)
plt.axvline(x=83,color='black', linestyle='dotted', linewidth=3)
plt.show()

from sklearn.metrics import ConfusionMatrixDisplay
from sklearn.metrics import confusion_matrix
import matplotlib.pyplot as plt
import numpy as np


cm = confusion_matrix(y_val, y_out)
labels = ['0', '1']
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)

disp.plot(cmap=plt.cm.Blues)
plt.title("Confusion Matrix for LSTM on Test Set")
plt.show()

